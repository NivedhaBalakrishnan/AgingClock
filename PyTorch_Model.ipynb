{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd59bcab-31d2-4703-8da3-69de1891417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03da4c2b-52a6-497f-974a-a26c1e3bc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path.cwd()/'models'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27b3206-e3fd-494a-89b6-fcf0e50521aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Eve(optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Eve Algorithm, proposed in `IMPROVING STOCHASTIC GRADIENT DESCENT WITH FEEDBACK`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999, 0.999), eps=1e-8,\n",
    "                 k=0.1, K=10, weight_decay=0):\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        k=k, K=K, weight_decay=weight_decay)\n",
    "        super(Eve, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure):\n",
    "        \"\"\"\n",
    "        :param closure: closure returns loss. see http://pytorch.org/docs/optim.html#optimizer-step-closure\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        loss = closure()\n",
    "        _loss = loss.item()  # float\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['m_t'] = grad.new().resize_as_(grad).zero_()\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['v_t'] = grad.new().resize_as_(grad).zero_()\n",
    "                    # f hats, smoothly tracked objective functions\n",
    "                    # \\hat{f}_0 = f_0\n",
    "                    state['ft_2'], state['ft_1'] = _loss, None\n",
    "                    state['d'] = 1\n",
    "\n",
    "                m_t, v_t = state['m_t'], state['v_t']\n",
    "                beta1, beta2, beta3 = group['betas']\n",
    "                k, K = group['k'], group['K']\n",
    "                d = state['d']\n",
    "                state['step'] += 1\n",
    "                t = state['step']\n",
    "                # initialization of \\hat{f}_1\n",
    "                if t == 1:\n",
    "                    # \\hat{f}_1 = f_1\n",
    "                    state['ft_1'] = _loss\n",
    "                # \\hat{f_{t-1}}, \\hat{f_{t-2}}\n",
    "                ft_1, ft_2 = state['ft_1'], state['ft_2']\n",
    "                # f(\\theta_{t-1})\n",
    "                f = _loss\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad = grad.add(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                m_t.mul_(beta1).add_(grad, alpha=1-beta1)\n",
    "                v_t.mul_(beta2).addcmul_(grad, grad, value=1-beta2)\n",
    "\n",
    "                m_t_hat = m_t / (1 - beta1 ** t)\n",
    "                v_t_hat = v_t / (1 - beta2 ** t)\n",
    "\n",
    "                if t > 1:\n",
    "                    if f >= state['ft_2']:\n",
    "                        delta = k + 1\n",
    "                        Delta = K + 1\n",
    "                    else:\n",
    "                        delta = 1 / (K + 1)\n",
    "                        Delta = 1 / (k + 1)\n",
    "\n",
    "                    c = min(max(delta, f / ft_2), Delta)\n",
    "                    r = abs(c - 1) / min(c, 1)\n",
    "                    state['ft_1'], state['ft_2'] = c * ft_2, ft_1\n",
    "                    state['d'] = beta3 * d + (1 - beta3) * r\n",
    "\n",
    "                # update parameters\n",
    "                p.data.addcdiv_(m_t_hat,\n",
    "                                v_t_hat.sqrt().add_(group['eps']),\n",
    "                                value=-group['lr']/state['d'])\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7442ac-437f-4773-9671-509b3dd4bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.drop(labels='AGE', axis=1).iloc[idx]\n",
    "        x = torch.from_numpy(x.values)\n",
    "        #returning y as a scalar might be a problem\n",
    "        y = self.df.iloc[idx].AGE\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3608f723-e1a8-4b8b-829d-095664aa6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layers, ps=0.35, in_features=20, y_range=(20, 90)):\n",
    "        super(NN, self).__init__()\n",
    "        self.y_range = y_range\n",
    "        self.layers = layers\n",
    "        self.ps = ps\n",
    "        layers = [in_features] + layers\n",
    "        layers = list(zip(layers, layers[1:]))\n",
    "        \n",
    "        l = []\n",
    "        for layer in layers:\n",
    "            l.append(nn.Linear(*layer))\n",
    "            #TODO: play with negative slope koef. of LeakyReLU\n",
    "            l.append(nn.LeakyReLU())\n",
    "            l.append(nn.Dropout(ps))\n",
    "        l.append(nn.Linear(layers[-1][1], 1))\n",
    "\n",
    "        self.arch = nn.Sequential(*l)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.arch(x)\n",
    "        x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Linear -> LeakyReLU -> Dropout\\nlayers: {}\\nps: {}\\n\".format(self.layers, self.ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92aa8b38-b226-4d8c-80d2-c77bdbd62c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, in_5_range = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).float(), y.to(device).float().unsqueeze(dim=1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            in_5_range += (abs(pred - y) < 5).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    in_5_range /= size\n",
    "    print(f\"Error: \\n Predictions in 5 range: {(100*in_5_range):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5cc239-9806-4c32-bf5c-649101dbc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device).float(), y.to(device).float().unsqueeze(dim=1)\n",
    "        if isinstance(optimizer, Eve):\n",
    "            loss = optimizer.step(closure)\n",
    "        else:\n",
    "            loss = closure()\n",
    "            optimizer.step()\n",
    "\n",
    "        #if batch % 300 == 299:\n",
    "            #loss, current = loss.item(), batch * len(X) + 1\n",
    "            #print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e223ce-c1c0-4964-9130-d4bce24071ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test(train_path='Data/train_data.csv', test_path='Data/test_data.csv',\n",
    "               optimizer=None, loss_fn=nn.L1Loss(), epochs=20, lr=1e-3,\n",
    "               layers=[1000,500,250], ps=0.35):\n",
    "\n",
    "    train_set = CustomDataset(pd.read_csv(train_path))\n",
    "    test_set = CustomDataset(pd.read_csv(test_path))\n",
    "    train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = NN(layers, ps=ps).to(device)\n",
    "    print(model, end='')\n",
    "    if not optimizer: \n",
    "        optimizer = Eve(model.parameters())\n",
    "        print('Optimizer: default EVE')\n",
    "    else: \n",
    "        optimizer = optimizer(model.parameters(), lr=lr)\n",
    "        print('Optimizer: {}\\nLearning rate: {}'.format(optimizer.__class__, lr))\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        print('Train ', end='')\n",
    "        test(train_dataloader, model, loss_fn)\n",
    "        print('Test ', end='')\n",
    "        test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1442af77-2674-4271-b82f-9074db267933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f1277e-66ce-4089-bee5-1c251da68d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear -> LeakyReLU -> Dropout\n",
      "layers: [1000, 500, 250]\n",
      "ps: 0.35\n",
      "Optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "Learning rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 30.5%, Avg loss: 10.645005 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.4%, Avg loss: 10.702228 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.1%, Avg loss: 10.281452 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.6%, Avg loss: 10.331845 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.6%, Avg loss: 10.137528 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.7%, Avg loss: 10.199069 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.8%, Avg loss: 10.018603 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.7%, Avg loss: 10.110163 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.0%, Avg loss: 9.937193 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.7%, Avg loss: 10.025865 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.5%, Avg loss: 9.915399 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 10.001666 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.6%, Avg loss: 9.837183 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.1%, Avg loss: 9.891124 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.8%, Avg loss: 9.776340 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.3%, Avg loss: 9.842493 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.7%, Avg loss: 9.756822 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.6%, Avg loss: 9.840171 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.7%, Avg loss: 9.739794 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.0%, Avg loss: 9.832267 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.5%, Avg loss: 9.773466 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.5%, Avg loss: 9.881891 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.1%, Avg loss: 9.670413 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 9.841043 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.4%, Avg loss: 9.636093 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 34.0%, Avg loss: 9.760522 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.8%, Avg loss: 9.654509 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.7%, Avg loss: 9.784754 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.6%, Avg loss: 9.592976 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.8%, Avg loss: 9.758966 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.6%, Avg loss: 9.591818 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.0%, Avg loss: 9.794562 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.0%, Avg loss: 9.595192 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.7%, Avg loss: 9.771696 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.6%, Avg loss: 9.564799 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.3%, Avg loss: 9.789861 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.9%, Avg loss: 9.580432 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.9%, Avg loss: 9.735821 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 34.2%, Avg loss: 9.574624 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.2%, Avg loss: 9.808557 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "440a2552-1e85-4ea2-a86c-ce4a3b73fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear -> LeakyReLU -> Dropout\n",
      "layers: [1000, 500, 250]\n",
      "ps: 0.5\n",
      "Optimizer: <class 'torch.optim.sgd.SGD'>\n",
      "Learning rate: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 29.7%, Avg loss: 10.857280 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 28.8%, Avg loss: 10.953143 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 30.7%, Avg loss: 10.486248 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.6%, Avg loss: 10.564447 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 31.9%, Avg loss: 10.307697 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.0%, Avg loss: 10.337654 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 31.9%, Avg loss: 10.212132 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.8%, Avg loss: 10.266271 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 31.6%, Avg loss: 10.178621 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.9%, Avg loss: 10.210541 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.4%, Avg loss: 10.098903 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.3%, Avg loss: 10.135917 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.0%, Avg loss: 10.075917 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.3%, Avg loss: 10.044133 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.0%, Avg loss: 10.057484 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.2%, Avg loss: 10.059637 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 31.5%, Avg loss: 10.105899 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.3%, Avg loss: 10.098520 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.6%, Avg loss: 9.947690 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.9%, Avg loss: 9.954596 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.1%, Avg loss: 9.923609 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 9.937229 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.5%, Avg loss: 9.917577 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.5%, Avg loss: 9.956432 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.3%, Avg loss: 9.914503 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.1%, Avg loss: 9.945181 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.1%, Avg loss: 9.881259 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.6%, Avg loss: 9.896237 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.9%, Avg loss: 9.841117 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.4%, Avg loss: 9.877487 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 32.9%, Avg loss: 9.822010 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.9%, Avg loss: 9.873252 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.6%, Avg loss: 9.801447 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 9.855359 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.4%, Avg loss: 9.769880 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 9.815302 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.8%, Avg loss: 9.736445 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.2%, Avg loss: 9.789845 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Predictions in 5 range: 33.6%, Avg loss: 9.748485 \n",
      "\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.3%, Avg loss: 9.797090 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(optimizer=sgd, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7558e8-8b77-4e32-bcb3-74e90b4cf495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear -> LeakyReLU -> Dropout\n",
      "layers: [1000, 500, 250]\n",
      "ps: 0.35\n",
      "Optimizer: default EVE\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 10.727507  [ 9569/20081]\n",
      "Train loss: 8.529991  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.5%, Avg loss: 10.278249 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 14.010041  [ 9569/20081]\n",
      "Train loss: 11.563896  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.4%, Avg loss: 10.128219 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 12.536409  [ 9569/20081]\n",
      "Train loss: 9.721921  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 28.9%, Avg loss: 10.681564 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 11.981577  [ 9569/20081]\n",
      "Train loss: 11.152709  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 29.5%, Avg loss: 10.756754 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 12.004296  [ 9569/20081]\n",
      "Train loss: 11.867448  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.8%, Avg loss: 10.347647 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 10.923096  [ 9569/20081]\n",
      "Train loss: 11.492233  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 29.9%, Avg loss: 10.596387 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 12.047308  [ 9569/20081]\n",
      "Train loss: 10.642256  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.8%, Avg loss: 10.094722 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 10.990910  [ 9569/20081]\n",
      "Train loss: 11.016297  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 29.8%, Avg loss: 10.701698 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 8.738873  [ 9569/20081]\n",
      "Train loss: 9.493444  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 29.5%, Avg loss: 10.364398 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 9.372708  [ 9569/20081]\n",
      "Train loss: 7.913949  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.5%, Avg loss: 10.135122 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 8.537163  [ 9569/20081]\n",
      "Train loss: 9.137678  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.7%, Avg loss: 10.286736 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 9.045336  [ 9569/20081]\n",
      "Train loss: 13.139945  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.7%, Avg loss: 10.532376 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 9.481878  [ 9569/20081]\n",
      "Train loss: 15.602877  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.6%, Avg loss: 10.066741 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 10.412086  [ 9569/20081]\n",
      "Train loss: 12.100823  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 34.0%, Avg loss: 9.927105 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 8.250042  [ 9569/20081]\n",
      "Train loss: 12.634984  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.8%, Avg loss: 10.154584 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 13.017939  [ 9569/20081]\n",
      "Train loss: 10.994295  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.7%, Avg loss: 10.110896 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 9.318192  [ 9569/20081]\n",
      "Train loss: 11.871534  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.0%, Avg loss: 10.067649 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 10.350759  [ 9569/20081]\n",
      "Train loss: 7.936570  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 34.1%, Avg loss: 10.235298 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 8.793219  [ 9569/20081]\n",
      "Train loss: 10.077761  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.7%, Avg loss: 10.839428 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 12.954304  [ 9569/20081]\n",
      "Train loss: 10.987885  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.7%, Avg loss: 10.822502 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0851e7-339c-49d3-8388-76b4a778f08c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear -> LeakyReLU -> Dropout\n",
      "layers: [1000, 500, 250]\n",
      "ps: 0.5\n",
      "Optimizer: default EVE\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 11.766499  [ 9569/20081]\n",
      "Train loss: 9.359514  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.8%, Avg loss: 10.284759 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 9.783750  [ 9569/20081]\n",
      "Train loss: 11.465638  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.0%, Avg loss: 10.499367 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 12.522458  [ 9569/20081]\n",
      "Train loss: 12.377500  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 29.7%, Avg loss: 10.554983 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 9.657304  [ 9569/20081]\n",
      "Train loss: 10.951116  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 28.8%, Avg loss: 10.867790 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 12.666935  [ 9569/20081]\n",
      "Train loss: 10.413408  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.6%, Avg loss: 10.548941 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 12.064486  [ 9569/20081]\n",
      "Train loss: 11.956337  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 28.7%, Avg loss: 10.608461 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 10.638474  [ 9569/20081]\n",
      "Train loss: 12.153069  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.5%, Avg loss: 10.285392 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 11.646702  [ 9569/20081]\n",
      "Train loss: 11.937624  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 33.3%, Avg loss: 10.222291 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 11.897242  [ 9569/20081]\n",
      "Train loss: 8.953284  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.1%, Avg loss: 10.921974 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 11.242042  [ 9569/20081]\n",
      "Train loss: 10.633278  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.0%, Avg loss: 10.148051 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 14.278829  [ 9569/20081]\n",
      "Train loss: 9.999903  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.4%, Avg loss: 10.360276 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 10.832792  [ 9569/20081]\n",
      "Train loss: 13.914697  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.5%, Avg loss: 10.321315 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 11.931841  [ 9569/20081]\n",
      "Train loss: 11.846249  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.5%, Avg loss: 10.680954 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 10.684555  [ 9569/20081]\n",
      "Train loss: 13.783357  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.6%, Avg loss: 10.370696 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 9.431915  [ 9569/20081]\n",
      "Train loss: 13.391575  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.5%, Avg loss: 10.219296 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 14.722255  [ 9569/20081]\n",
      "Train loss: 13.420494  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.8%, Avg loss: 10.431304 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 11.427352  [ 9569/20081]\n",
      "Train loss: 11.742826  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 32.1%, Avg loss: 10.255008 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 11.426344  [ 9569/20081]\n",
      "Train loss: 12.905696  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 30.9%, Avg loss: 10.432336 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 13.233578  [ 9569/20081]\n",
      "Train loss: 13.341002  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 31.0%, Avg loss: 10.347745 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 10.617232  [ 9569/20081]\n",
      "Train loss: 10.879385  [19169/20081]\n",
      "Test Error: \n",
      " Predictions in 5 range: 28.4%, Avg loss: 10.734143 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test(ps=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
